{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dress_Code_Mask_RCNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Installation of Object Detection API"
      ],
      "metadata": {
        "id": "JJfnsb_KiVPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn_DsAFW4EXY",
        "outputId": "4ceec1a5-6e07-4a46-8a69-638271b5ac82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jhzeg9HGibHq",
        "outputId": "d42d59ed-8381-4582-f472-64fa496e5525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msXFw9oUiiPN",
        "outputId": "df2f01d7-4999-469f-9ff5-121860c0c778"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/CatchZeng/object-detection-api.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gcaRrZVi2wO",
        "outputId": "e092b162-135f-4132-920c-6eea1d9b3171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'object-detection-api'...\n",
            "remote: Enumerating objects: 365, done.\u001b[K\n",
            "remote: Counting objects: 100% (365/365), done.\u001b[K\n",
            "remote: Compressing objects: 100% (238/238), done.\u001b[K\n",
            "remote: Total 365 (delta 138), reused 321 (delta 94), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (365/365), 1.78 MiB | 7.74 MiB/s, done.\n",
            "Resolving deltas: 100% (138/138), done.\n",
            "Checking out files: 100% (134/134), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oB6ocpbjPO1",
        "outputId": "5a97e7c6-aa1f-4bcc-d41d-3cf61491014c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dress_Code_Mask_RCNN.ipynb  object-detection-api\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd object-detection-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYNJPscJjety",
        "outputId": "19cdb281-b9e0-4021-9311-a457083e4632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install labelme"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG6BaZVnn73g",
        "outputId": "ae5d36cc-1055-48bb-8527-bf50ce8ed8a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting labelme\n",
            "  Downloading labelme-5.0.1.tar.gz (1.5 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 25.8 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 92 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 133 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 174 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 184 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 194 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 204 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 215 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 225 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 235 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 245 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 256 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 266 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 276 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 286 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 296 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 307 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 317 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 327 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 337 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 348 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 358 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 368 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 378 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 389 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 399 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 409 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 419 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 430 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 440 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 450 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 460 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 471 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 481 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 491 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 501 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 512 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 522 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 532 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 542 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 552 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 563 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 573 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 583 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 593 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 604 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 614 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 624 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 634 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 645 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 655 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 665 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 675 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 686 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 696 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 706 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 716 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 727 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 737 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 747 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 757 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 768 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 778 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 788 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 798 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 808 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 819 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 829 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 839 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 849 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 860 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 870 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 880 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 890 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 901 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 911 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 921 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 931 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 942 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 952 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 962 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 972 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 983 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 993 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.0 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.0 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.0 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.0 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.2 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.3 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.4 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.5 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5 MB 12.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.5 MB 12.2 MB/s \n",
            "\u001b[?25hCollecting imgviz>=0.11\n",
            "  Downloading imgviz-1.5.0.tar.gz (7.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.7 MB 33.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib<3.3 in /usr/local/lib/python3.7/dist-packages (from labelme) (3.2.2)\n",
            "Collecting natsort>=7.1.0\n",
            "  Downloading natsort-8.1.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from labelme) (1.21.5)\n",
            "Requirement already satisfied: Pillow>=2.8 in /usr/local/lib/python3.7/dist-packages (from labelme) (7.1.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from labelme) (3.13)\n",
            "Requirement already satisfied: qtpy!=1.11.2 in /usr/local/lib/python3.7/dist-packages (from labelme) (2.0.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from labelme) (1.1.0)\n",
            "Collecting PyQt5!=5.15.3,!=5.15.4\n",
            "  Downloading PyQt5-5.15.6-cp36-abi3-manylinux1_x86_64.whl (8.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.3 MB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3->labelme) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3->labelme) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3->labelme) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib<3.3->labelme) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib<3.3->labelme) (3.10.0.2)\n",
            "Collecting PyQt5-Qt5>=5.15.2\n",
            "  Downloading PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.9 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting PyQt5-sip<13,>=12.8\n",
            "  Downloading PyQt5_sip-12.9.1-cp37-cp37m-manylinux1_x86_64.whl (338 kB)\n",
            "\u001b[K     |████████████████████████████████| 338 kB 44.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib<3.3->labelme) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from qtpy!=1.11.2->labelme) (21.3)\n",
            "Building wheels for collected packages: labelme, imgviz\n",
            "  Building wheel for labelme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for labelme: filename=labelme-5.0.1-py3-none-any.whl size=1466204 sha256=19fe242ca51b9576a5bdbd7dd01169ce968e3c068a56e5f53226f19fecb52ff5\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/f1/e1/84b4d6e95299dbc58c1616c63622624e39643ee591866cfd1e\n",
            "  Building wheel for imgviz (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgviz: filename=imgviz-1.5.0-py3-none-any.whl size=7680458 sha256=eb667ad5523a5b145991af9dd2876573f6860a17ff5303e43e779c63c93a98d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/36/f3/3c810b6e34387a0307f93d39805fa653742897568f5a3e8080\n",
            "Successfully built labelme imgviz\n",
            "Installing collected packages: PyQt5-sip, PyQt5-Qt5, PyQt5, natsort, imgviz, labelme\n",
            "  Attempting uninstall: natsort\n",
            "    Found existing installation: natsort 5.5.0\n",
            "    Uninstalling natsort-5.5.0:\n",
            "      Successfully uninstalled natsort-5.5.0\n",
            "Successfully installed PyQt5-5.15.6 PyQt5-Qt5-5.15.2 PyQt5-sip-12.9.1 imgviz-1.5.0 labelme-5.0.1 natsort-8.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR5MldX5Kh_c",
        "outputId": "d07b7efe-7518-4ed6-a4f4-49459038e726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (21.1.3)\n",
            "Collecting pip\n",
            "  Downloading pip-22.0.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 13.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 21.1.3\n",
            "    Uninstalling pip-21.1.3:\n",
            "      Successfully uninstalled pip-21.1.3\n",
            "Successfully installed pip-22.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEJ-gTBHjiPZ",
        "outputId": "d1418107-2c59-40d7-d594-ffc6d727df9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if [ -d \"./models\" ]; then \\\n",
            "    echo 'models downloaded'; \\\n",
            "  else \\\n",
            "        git clone --depth=1 https://github.com/tensorflow/models; \\\n",
            "fi\n",
            "models downloaded\n",
            "cd models/research && \\\n",
            "protoc object_detection/protos/*.proto --python_out=. && \\\n",
            "cp object_detection/packages/tf2/setup.py . && \\\n",
            "python -m pip install --use-feature=2020-resolver .\n",
            "\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\u001b[33m\n",
            "\u001b[0mProcessing /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam\n",
            "  Downloading apache_beam-2.37.0-cp37-cp37m-manylinux2010_x86_64.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.28)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.4)\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
            "Collecting tf-models-official>=2.5.1\n",
            "  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io\n",
            "  Downloading tensorflow_io-0.24.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.4/23.4 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Collecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.6/237.6 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/99.8 KB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyyaml<6.0,>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.6/636.6 KB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 KB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.21.5)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n",
            "Collecting tensorflow-text~=2.8.0\n",
            "  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->object-detection==0.1) (2018.9)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim->object-detection==0.1) (1.0.0)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: pyarrow<7.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
            "Collecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
            "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.10.0.2)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.4.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.1/508.1 KB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
            "  Downloading proto_plus-1.20.3-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 KB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.44.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.17.3)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.6.7-cp37-cp37m-manylinux_2_24_x86_64.whl (255 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.4/255.4 KB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 KB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests<3.0.0,>=2.24.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (3.0.7)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.24.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_io->object-detection==0.1) (0.24.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.63.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.10.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
            "Collecting protobuf<4,>=3.12.2\n",
            "  Downloading protobuf-3.20.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.8.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 KB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (13.0.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.4.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.4.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.7.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (4.11.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Building wheels for collected packages: object-detection, avro-python3, dill, py-cpuinfo, seqeval\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=21908001 sha256=14825f74b1417353b8a3f67fd4fe0b551ac852866716756e7b6d95bfc61278b4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-50gftvyi/wheels/96/c5/63/7f695ea7cf1fdb9ae1b08d57860b7bf38076c43ba1b87c4a99\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=b319ebd598de669470985e0590136ac6121e2d6508ba525cf005b4e6e7c800cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=c8cb115470e62ea8f81f864f964a12a92a3dc93ca75e8a3af7b751facf3e1f4a\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=dcce0a7cd9b120f585c04e092fab4a1ae2132118652f12bfff2968b0f12e270b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=6a48c144860b7eda3261ace3c35c94a144c0be6222efed487106f6092a3ce206\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built object-detection avro-python3 dill py-cpuinfo seqeval\n",
            "Installing collected packages: tf-estimator-nightly, sentencepiece, py-cpuinfo, tensorflow_io, tensorflow-addons, requests, pyyaml, pymongo, protobuf, portalocker, orjson, opencv-python-headless, fastavro, dill, colorama, cloudpickle, avro-python3, tf-slim, tensorflow-model-optimization, sacrebleu, proto-plus, hdfs, seqeval, lvis, apache-beam, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.0.2\n",
            "    Uninstalling pymongo-4.0.2:\n",
            "      Successfully uninstalled pymongo-4.0.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.4\n",
            "    Uninstalling dill-0.3.4:\n",
            "      Successfully uninstalled dill-0.3.4\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache-beam-2.37.0 avro-python3-1.10.2 cloudpickle-2.0.0 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.10 hdfs-2.7.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.5.64 orjson-3.6.7 portalocker-2.4.0 proto-plus-1.20.3 protobuf-3.20.0 py-cpuinfo-8.0.0 pymongo-3.12.3 pyyaml-5.4.1 requests-2.27.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-model-optimization-0.7.2 tensorflow-text-2.8.1 tensorflow_io-0.24.0 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0 tf-slim-1.1.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mcd models/research && \\\n",
            "python object_detection/builders/model_builder_tf2_test.py\n",
            "Running tests under Python 3.7.13: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "2022-04-04 06:09:26.862864: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "W0404 06:09:27.386978 139654481745792 model_builder.py:1100] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.79s\n",
            "I0404 06:09:27.724550 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.79s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.74s\n",
            "I0404 06:09:28.466084 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.74s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\n",
            "I0404 06:09:28.815870 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.3s\n",
            "I0404 06:09:29.115092 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.3s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.64s\n",
            "I0404 06:09:31.754260 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.64s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I0404 06:09:31.755437 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "I0404 06:09:31.797179 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.04s\n",
            "I0404 06:09:31.841285 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "I0404 06:09:31.875987 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
            "I0404 06:09:32.020038 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n",
            "I0404 06:09:32.135325 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n",
            "I0404 06:09:32.255643 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.15s\n",
            "I0404 06:09:32.407557 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
            "I0404 06:09:32.529004 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "I0404 06:09:32.561713 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I0404 06:09:32.792730 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I0404 06:09:32.792909 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64\n",
            "I0404 06:09:32.793028 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3\n",
            "I0404 06:09:32.795565 139654481745792 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0404 06:09:32.816048 139654481745792 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0404 06:09:32.816174 139654481745792 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0404 06:09:32.891320 139654481745792 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0404 06:09:32.891462 139654481745792 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0404 06:09:33.196910 139654481745792 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0404 06:09:33.197188 139654481745792 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0404 06:09:33.426815 139654481745792 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0404 06:09:33.427058 139654481745792 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0404 06:09:33.970268 139654481745792 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0404 06:09:33.970480 139654481745792 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0404 06:09:34.247811 139654481745792 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0404 06:09:34.248005 139654481745792 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0404 06:09:34.637859 139654481745792 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0404 06:09:34.638076 139654481745792 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I0404 06:09:34.733404 139654481745792 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I0404 06:09:34.768976 139654481745792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0404 06:09:34.832358 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I0404 06:09:34.832552 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88\n",
            "I0404 06:09:34.832658 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4\n",
            "I0404 06:09:34.834448 139654481745792 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0404 06:09:34.852297 139654481745792 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0404 06:09:34.852476 139654481745792 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0404 06:09:34.999075 139654481745792 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0404 06:09:34.999259 139654481745792 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0404 06:09:35.290242 139654481745792 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0404 06:09:35.290460 139654481745792 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0404 06:09:35.578598 139654481745792 efficientnet_model.py:144] round_filter input=40 output=40\n",
            "I0404 06:09:35.578810 139654481745792 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0404 06:09:35.956304 139654481745792 efficientnet_model.py:144] round_filter input=80 output=80\n",
            "I0404 06:09:35.956540 139654481745792 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0404 06:09:36.327288 139654481745792 efficientnet_model.py:144] round_filter input=112 output=112\n",
            "I0404 06:09:36.327586 139654481745792 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0404 06:09:36.822637 139654481745792 efficientnet_model.py:144] round_filter input=192 output=192\n",
            "I0404 06:09:36.822852 139654481745792 efficientnet_model.py:144] round_filter input=320 output=320\n",
            "I0404 06:09:37.026105 139654481745792 efficientnet_model.py:144] round_filter input=1280 output=1280\n",
            "I0404 06:09:37.063201 139654481745792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0404 06:09:37.164264 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I0404 06:09:37.164489 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112\n",
            "I0404 06:09:37.164608 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5\n",
            "I0404 06:09:37.166635 139654481745792 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0404 06:09:37.185985 139654481745792 efficientnet_model.py:144] round_filter input=32 output=32\n",
            "I0404 06:09:37.186200 139654481745792 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0404 06:09:37.347037 139654481745792 efficientnet_model.py:144] round_filter input=16 output=16\n",
            "I0404 06:09:37.347246 139654481745792 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0404 06:09:37.660205 139654481745792 efficientnet_model.py:144] round_filter input=24 output=24\n",
            "I0404 06:09:37.660428 139654481745792 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0404 06:09:37.969010 139654481745792 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0404 06:09:37.969220 139654481745792 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I0404 06:09:38.353890 139654481745792 efficientnet_model.py:144] round_filter input=80 output=88\n",
            "I0404 06:09:38.354091 139654481745792 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I0404 06:09:38.741690 139654481745792 efficientnet_model.py:144] round_filter input=112 output=120\n",
            "I0404 06:09:38.741907 139654481745792 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I0404 06:09:39.550029 139654481745792 efficientnet_model.py:144] round_filter input=192 output=208\n",
            "I0404 06:09:39.550356 139654481745792 efficientnet_model.py:144] round_filter input=320 output=352\n",
            "I0404 06:09:39.762336 139654481745792 efficientnet_model.py:144] round_filter input=1280 output=1408\n",
            "I0404 06:09:39.800189 139654481745792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0404 06:09:39.891313 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I0404 06:09:39.891583 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160\n",
            "I0404 06:09:39.891708 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6\n",
            "I0404 06:09:39.893797 139654481745792 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I0404 06:09:39.915673 139654481745792 efficientnet_model.py:144] round_filter input=32 output=40\n",
            "I0404 06:09:39.915880 139654481745792 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0404 06:09:40.073198 139654481745792 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0404 06:09:40.073432 139654481745792 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0404 06:09:40.376693 139654481745792 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0404 06:09:40.376898 139654481745792 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0404 06:09:40.684098 139654481745792 efficientnet_model.py:144] round_filter input=40 output=48\n",
            "I0404 06:09:40.684288 139654481745792 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I0404 06:09:41.225192 139654481745792 efficientnet_model.py:144] round_filter input=80 output=96\n",
            "I0404 06:09:41.225394 139654481745792 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I0404 06:09:41.750509 139654481745792 efficientnet_model.py:144] round_filter input=112 output=136\n",
            "I0404 06:09:41.750789 139654481745792 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I0404 06:09:42.334705 139654481745792 efficientnet_model.py:144] round_filter input=192 output=232\n",
            "I0404 06:09:42.335013 139654481745792 efficientnet_model.py:144] round_filter input=320 output=384\n",
            "I0404 06:09:42.525155 139654481745792 efficientnet_model.py:144] round_filter input=1280 output=1536\n",
            "I0404 06:09:42.561026 139654481745792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0404 06:09:42.653547 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I0404 06:09:42.653798 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224\n",
            "I0404 06:09:42.653935 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0404 06:09:42.657050 139654481745792 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0404 06:09:42.677333 139654481745792 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0404 06:09:42.677464 139654481745792 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0404 06:09:42.830285 139654481745792 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0404 06:09:42.830504 139654481745792 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0404 06:09:43.287843 139654481745792 efficientnet_model.py:144] round_filter input=24 output=32\n",
            "I0404 06:09:43.288073 139654481745792 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I0404 06:09:43.693279 139654481745792 efficientnet_model.py:144] round_filter input=40 output=56\n",
            "I0404 06:09:43.693558 139654481745792 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I0404 06:09:44.279838 139654481745792 efficientnet_model.py:144] round_filter input=80 output=112\n",
            "I0404 06:09:44.280043 139654481745792 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I0404 06:09:44.853875 139654481745792 efficientnet_model.py:144] round_filter input=112 output=160\n",
            "I0404 06:09:44.854184 139654481745792 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I0404 06:09:45.666015 139654481745792 efficientnet_model.py:144] round_filter input=192 output=272\n",
            "I0404 06:09:45.666232 139654481745792 efficientnet_model.py:144] round_filter input=320 output=448\n",
            "I0404 06:09:46.132439 139654481745792 efficientnet_model.py:144] round_filter input=1280 output=1792\n",
            "I0404 06:09:46.167207 139654481745792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0404 06:09:46.256896 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I0404 06:09:46.257129 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288\n",
            "I0404 06:09:46.257295 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7\n",
            "I0404 06:09:46.260924 139654481745792 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0404 06:09:46.291987 139654481745792 efficientnet_model.py:144] round_filter input=32 output=48\n",
            "I0404 06:09:46.292120 139654481745792 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0404 06:09:46.525331 139654481745792 efficientnet_model.py:144] round_filter input=16 output=24\n",
            "I0404 06:09:46.525570 139654481745792 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0404 06:09:47.054697 139654481745792 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0404 06:09:47.055011 139654481745792 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I0404 06:09:47.563649 139654481745792 efficientnet_model.py:144] round_filter input=40 output=64\n",
            "I0404 06:09:47.563888 139654481745792 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I0404 06:09:48.251123 139654481745792 efficientnet_model.py:144] round_filter input=80 output=128\n",
            "I0404 06:09:48.251376 139654481745792 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I0404 06:09:48.925909 139654481745792 efficientnet_model.py:144] round_filter input=112 output=176\n",
            "I0404 06:09:48.926115 139654481745792 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I0404 06:09:49.883985 139654481745792 efficientnet_model.py:144] round_filter input=192 output=304\n",
            "I0404 06:09:49.884189 139654481745792 efficientnet_model.py:144] round_filter input=320 output=512\n",
            "I0404 06:09:50.165153 139654481745792 efficientnet_model.py:144] round_filter input=1280 output=2048\n",
            "I0404 06:09:50.200461 139654481745792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0404 06:09:50.308773 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I0404 06:09:50.309071 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0404 06:09:50.309178 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0404 06:09:50.311330 139654481745792 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I0404 06:09:50.332006 139654481745792 efficientnet_model.py:144] round_filter input=32 output=56\n",
            "I0404 06:09:50.332148 139654481745792 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0404 06:09:50.567373 139654481745792 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0404 06:09:50.567644 139654481745792 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0404 06:09:51.157696 139654481745792 efficientnet_model.py:144] round_filter input=24 output=40\n",
            "I0404 06:09:51.157893 139654481745792 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I0404 06:09:51.739627 139654481745792 efficientnet_model.py:144] round_filter input=40 output=72\n",
            "I0404 06:09:51.739906 139654481745792 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I0404 06:09:52.535131 139654481745792 efficientnet_model.py:144] round_filter input=80 output=144\n",
            "I0404 06:09:52.535356 139654481745792 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I0404 06:09:53.611722 139654481745792 efficientnet_model.py:144] round_filter input=112 output=200\n",
            "I0404 06:09:53.611952 139654481745792 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I0404 06:09:54.762306 139654481745792 efficientnet_model.py:144] round_filter input=192 output=344\n",
            "I0404 06:09:54.762635 139654481745792 efficientnet_model.py:144] round_filter input=320 output=576\n",
            "I0404 06:09:55.054157 139654481745792 efficientnet_model.py:144] round_filter input=1280 output=2304\n",
            "I0404 06:09:55.090236 139654481745792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I0404 06:09:55.228216 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I0404 06:09:55.228419 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384\n",
            "I0404 06:09:55.228555 139654481745792 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8\n",
            "I0404 06:09:55.230666 139654481745792 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I0404 06:09:55.249655 139654481745792 efficientnet_model.py:144] round_filter input=32 output=64\n",
            "I0404 06:09:55.249801 139654481745792 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0404 06:09:55.576367 139654481745792 efficientnet_model.py:144] round_filter input=16 output=32\n",
            "I0404 06:09:55.576590 139654481745792 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I0404 06:09:56.296316 139654481745792 efficientnet_model.py:144] round_filter input=24 output=48\n",
            "I0404 06:09:56.296563 139654481745792 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I0404 06:09:56.982740 139654481745792 efficientnet_model.py:144] round_filter input=40 output=80\n",
            "I0404 06:09:56.983037 139654481745792 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I0404 06:09:58.186063 139654481745792 efficientnet_model.py:144] round_filter input=80 output=160\n",
            "I0404 06:09:58.186390 139654481745792 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I0404 06:09:59.227623 139654481745792 efficientnet_model.py:144] round_filter input=112 output=224\n",
            "I0404 06:09:59.227843 139654481745792 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I0404 06:10:00.807122 139654481745792 efficientnet_model.py:144] round_filter input=192 output=384\n",
            "I0404 06:10:00.807347 139654481745792 efficientnet_model.py:144] round_filter input=320 output=640\n",
            "I0404 06:10:01.207812 139654481745792 efficientnet_model.py:144] round_filter input=1280 output=2560\n",
            "I0404 06:10:01.244762 139654481745792 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 28.83s\n",
            "I0404 06:10:01.388190 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 28.83s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "I0404 06:10:01.395910 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I0404 06:10:01.398005 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I0404 06:10:01.398667 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I0404 06:10:01.400631 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I0404 06:10:01.402457 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I0404 06:10:01.403059 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I0404 06:10:01.404316 139654481745792 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 37.466s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ykj0TOgojkbY",
        "outputId": "ea33776d-a03d-4b39-fba0-31706cd870f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training"
      ],
      "metadata": {
        "id": "-2gfjGTAuWF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!make workspace-mask SAVE_DIR=workspace NAME=Dress-Code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPf4ThVumPLN",
        "outputId": "7023e88e-8252-4972-9492-83ff1b408414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python scripts/workspace/mask/workspace.py --save_dir=workspace --name=Dress-Code\n",
            "cp -r scripts/workspace/mask/files/* workspace/Dress-Code\n",
            "python scripts/workspace/mask/replace.py --dir=workspace/Dress-Code --pattern=\"{{.Name}}\" --repl=Dress-Code\n",
            "ignore COCO_Image_Viewer.ipynb\n",
            "['workspace/Dress-Code/create_coco_tf_record.py', 'workspace/Dress-Code/deployments/flask/Dockerfile', 'workspace/Dress-Code/deployments/flask/Makefile', 'workspace/Dress-Code/deployments/flask/api.py', 'workspace/Dress-Code/deployments/flask/app.py', 'workspace/Dress-Code/deployments/flask/file.py', 'workspace/Dress-Code/deployments/flask/model.py', 'workspace/Dress-Code/deployments/flask/nginx.conf', 'workspace/Dress-Code/deployments/flask/object_detection/protos/string_int_label_map.proto', 'workspace/Dress-Code/deployments/flask/object_detection/protos/string_int_label_map_pb2.py', 'workspace/Dress-Code/deployments/flask/object_detection/utils/label_map_util.py', 'workspace/Dress-Code/deployments/flask/object_detection/utils/ops.py', 'workspace/Dress-Code/deployments/flask/object_detection/utils/visualization_utils.py', 'workspace/Dress-Code/deployments/serving/client.py', 'workspace/Dress-Code/gen_label_map.py', 'workspace/Dress-Code/labelme2coco.py', 'workspace/Dress-Code/Makefile', 'workspace/Dress-Code/test_images.py']\n",
            "cp models/research/object_detection/model_main_tf2.py workspace/Dress-Code\n",
            "cp models/research/object_detection/exporter_main_v2.py workspace/Dress-Code\n",
            "touch workspace/Dress-Code/annotations/label_map.pbtxt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd \"/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxap-IhDmch1",
        "outputId": "4870fc16-b9dc-4cb0-f333-c7294716bdc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make gen-tfrecord"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl2CUPUUmm_f",
        "outputId": "fda8938a-35e6-4146-f8b2-406ea4820cb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python labelme2coco.py images/train --output images/train.json\n",
            "save coco json\n",
            "images/train.json\n",
            "python labelme2coco.py images/val --output images/val.json\n",
            "save coco json\n",
            "images/val.json\n",
            "python create_coco_tf_record.py --logtostderr \\\n",
            "--train_image_dir=images/train \\\n",
            "--val_image_dir=images/val \\\n",
            "--train_annotations_file=images/train.json \\\n",
            "--val_annotations_file=images/val.json \\\n",
            "--include_masks=True \\\n",
            "--output_dir=./annotations\n",
            "INFO:tensorflow:Found groundtruth annotations. Building annotations index.\n",
            "I0314 16:49:54.174854 139849212225408 create_coco_tf_record.py:195] Found groundtruth annotations. Building annotations index.\n",
            "INFO:tensorflow:0 images are missing annotations.\n",
            "I0314 16:49:54.175096 139849212225408 create_coco_tf_record.py:208] 0 images are missing annotations.\n",
            "INFO:tensorflow:On image 0 of 15\n",
            "I0314 16:49:54.175391 139849212225408 create_coco_tf_record.py:213] On image 0 of 15\n",
            "INFO:tensorflow:Finished writing, skipped 0 annotations.\n",
            "I0314 16:49:59.469888 139849212225408 create_coco_tf_record.py:221] Finished writing, skipped 0 annotations.\n",
            "INFO:tensorflow:Found groundtruth annotations. Building annotations index.\n",
            "I0314 16:49:59.477100 139849212225408 create_coco_tf_record.py:195] Found groundtruth annotations. Building annotations index.\n",
            "INFO:tensorflow:0 images are missing annotations.\n",
            "I0314 16:49:59.477285 139849212225408 create_coco_tf_record.py:208] 0 images are missing annotations.\n",
            "INFO:tensorflow:On image 0 of 13\n",
            "I0314 16:49:59.477424 139849212225408 create_coco_tf_record.py:213] On image 0 of 13\n",
            "INFO:tensorflow:Finished writing, skipped 0 annotations.\n",
            "I0314 16:50:03.788272 139849212225408 create_coco_tf_record.py:221] Finished writing, skipped 0 annotations.\n",
            "python gen_label_map.py\n",
            "item {\n",
            "  id: 1\n",
            "  name: 'pant'\n",
            "}\n",
            "\n",
            "item {\n",
            "  id: 2\n",
            "  name: 'shirt'\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-pXmlVsnvzY",
        "outputId": "12b128d0-0861-4c09-ab52-75e0d3ee3a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make dl-model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrkdQXj5pW_c",
        "outputId": "8a326802-b9ec-410c-9764-cceed75eebe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir -p pre-trained-models; \\\n",
            "model=mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8; \\\n",
            "curl -O http://download.tensorflow.org/models/object_detection/tf2/20200711/$model.tar.gz; \\\n",
            "tar zxvf $model.tar.gz; \\\n",
            "mv -f $model ./pre-trained-models/; \\\n",
            "rm -rf $model $model.tar.gz;\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  462M  100  462M    0     0  53.8M      0  0:00:08  0:00:08 --:--:-- 59.2M\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/checkpoint\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0.index\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/saved_model.pb\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/assets/\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B-udOMVpYf3",
        "outputId": "ff515f25-573f-4956-b521-3875138109ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless==4.5.5.62\n",
        "!pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QXA2BYTtMVn",
        "outputId": "77723bf2-6dee-4294-b97d-f3945c3e2707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python-headless 4.5.5.64\n",
            "Uninstalling opencv-python-headless-4.5.5.64:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.5.5.64.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-65fa80df.so.58.134.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-8ef5c7db.so.58.76.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-9c768859.so.56.70.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-09fe7800.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libgfortran-91cc3cb1.so.3.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libopenblas-r0-f650aae0.3.3.so\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-b92f8066.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-99364a1c.so.3.9.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-e6451464.so.5.9.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-1016051d.so.7.0.0\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtCore-bbdab771.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtGui-903938cd.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavcodec-3cdd3bd4.so.58.62.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavformat-69a63b50.so.58.35.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavutil-8e8979a8.so.56.36.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libbz2-7225278b.so.1.0.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libcrypto-a25ff511.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libssl-fdf0b66c.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswresample-c6b3bbb9.so.3.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswscale-2d19f7d1.so.5.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libvpx-c887ea55.so.6.1.0\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled opencv-python-headless-4.5.5.64\n",
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.5)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrN8tUJHs5XM",
        "outputId": "3a55b368-d830-472d-e250-f7d3c93bcd26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python model_main_tf2.py \\\n",
            "--model_dir=models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8 \\\n",
            "--pipeline_config_path=models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/pipeline.config\n",
            "2022-03-14 16:52:59.711350: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0314 16:52:59.717823 140120051074944 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0314 16:52:59.723666 140120051074944 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0314 16:52:59.723842 140120051074944 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0314 16:52:59.771576 140120051074944 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['annotations/train.record']\n",
            "I0314 16:52:59.787800 140120051074944 dataset_builder.py:163] Reading unweighted datasets: ['annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['annotations/train.record']\n",
            "I0314 16:52:59.788260 140120051074944 dataset_builder.py:80] Reading record datasets for input file: ['annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0314 16:52:59.788414 140120051074944 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0314 16:52:59.788549 140120051074944 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0314 16:52:59.795408 140120051074944 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0314 16:52:59.825208 140120051074944 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0314 16:53:02.188569 140120051074944 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0314 16:53:08.392480 140120051074944 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0314 16:53:11.627366 140120051074944 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0314 16:53:31.714996 140115272238848 convolutional_keras_box_predictor.py:154] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0314 16:53:38.417390 140115272238848 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n",
            "W0314 16:53:38.987179 140115272238848 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use ref() instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0314 16:53:42.936021 140115272238848 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0314 16:53:48.111031 140115272238848 deprecation.py:343] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0314 16:54:31.774253 140120051074944 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0314 16:54:31.775716 140120051074944 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0314 16:54:31.777885 140120051074944 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0314 16:54:31.779001 140120051074944 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0314 16:54:31.781122 140120051074944 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0314 16:54:31.782283 140120051074944 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0314 16:54:31.784420 140120051074944 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0314 16:54:31.785557 140120051074944 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0314 16:54:31.787904 140120051074944 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0314 16:54:31.789047 140120051074944 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0314 16:54:33.894362 140115297416960 deprecation.py:547] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "Makefile:22: recipe for target 'train' failed\n",
            "make: *** [train] Killed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-rR8Hph9s8bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Nvl7sIj9B8yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dErCBTbVB80b",
        "outputId": "b69a92d8-c2bb-456f-e2f6-145325b3e379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd workspace/test-mask/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfX04vjBDzCW",
        "outputId": "62505221-6534-4ded-e56a-6697bae30c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/test-mask\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python test_images.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPDt9iO1B84b",
        "outputId": "c85932ec-3065-45cd-e772-c8c96a0b96bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-21 06:19:47.571099: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Loading model...Done! Took 39.66986966133118 seconds\n",
            "Running inference for ./images/test/68.jpg... Running inference for ./images/test/128.jpg... Running inference for ./images/test/148.jpg... Running inference for ./images/test/146.jpg... Running inference for ./images/test/115.jpg... Running inference for ./images/test/64.jpg... Running inference for ./images/test/6.jpg... Running inference for ./images/test/401.jpg... Running inference for ./images/test/423.jpg... Running inference for ./images/test/288.jpg... Running inference for ./images/test/291.jpg... Running inference for ./images/test/294.jpg... Running inference for ./images/test/495.jpg... Running inference for ./images/test/508.jpg... Running inference for ./images/test/13.jpg... Running inference for ./images/test/53.jpg... Running inference for ./images/test/img10.jpg... Running inference for ./images/test/person.jpg... Running inference for ./images/test/43.jpg... Running inference for ./images/test/44.jpg... Done!\n",
            "Annotated images is at ./images/test_annotated/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ums4is-7KCrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall opencv-python-headless==4.5.5.62\n",
        "!pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfe-dloAKCzY",
        "outputId": "d80ecf23-9dc6-42d9-cbc7-44e699d96f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: opencv-python-headless 4.5.5.64\n",
            "Uninstalling opencv-python-headless-4.5.5.64:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.5.5.64.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-65fa80df.so.58.134.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-8ef5c7db.so.58.76.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-9c768859.so.56.70.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-09fe7800.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libgfortran-91cc3cb1.so.3.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libopenblas-r0-f650aae0.3.3.so\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-b92f8066.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-99364a1c.so.3.9.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-e6451464.so.5.9.100\n",
            "    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-1016051d.so.7.0.0\n",
            "  Would not remove (might be manually added):\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtCore-bbdab771.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtGui-903938cd.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavcodec-3cdd3bd4.so.58.62.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavformat-69a63b50.so.58.35.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavutil-8e8979a8.so.56.36.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libbz2-7225278b.so.1.0.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libcrypto-a25ff511.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libssl-fdf0b66c.so.1.1\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswresample-c6b3bbb9.so.3.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswscale-2d19f7d1.so.5.6.100\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libvpx-c887ea55.so.6.1.0\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3\n",
            "    /usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled opencv-python-headless-4.5.5.64\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.5)\n",
            "Installing collected packages: opencv-python-headless\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IUhHs677Fu0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKTDkICVFu84",
        "outputId": "2e0e63b7-a4b6-4533-ad6a-56c3b2fe1b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UGXzyy4JUrE",
        "outputId": "9c58c8dd-5d11-4b15-f5d7-c49fb5120564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inferencing Model on Video Input"
      ],
      "metadata": {
        "id": "KG8nyfzwFwfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from PIL import Image\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n"
      ],
      "metadata": {
        "id": "EsTggdUgKC2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_LABELS = './annotations/label_map.pbtxt'\n",
        "PATH_TO_SAVED_MODEL = './exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8' + \"/saved_model\"\n",
        "PATH_TO_VIDEO = '/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/test1.mp4'"
      ],
      "metadata": {
        "id": "6RdSKOvNNtrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cam = cv2.VideoCapture(PATH_TO_VIDEO)"
      ],
      "metadata": {
        "id": "NFAGzb6JON8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# frame\n",
        "currentframe = 0\n",
        "  \n",
        "while(True):\n",
        "      \n",
        "    # reading from frame\n",
        "    ret,frame = cam.read()\n",
        "  \n",
        "    if ret:\n",
        "        # if video is still left continue creating images\n",
        "        name = '/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame' + str(currentframe) + '.jpg'\n",
        "        print ('Creating...' + name)\n",
        "  \n",
        "        # writing the extracted images\n",
        "        cv2.imwrite(name, frame)\n",
        "  \n",
        "        # increasing counter so that it will\n",
        "        # show how many frames are created\n",
        "        currentframe += 1\n",
        "    else:\n",
        "        break\n",
        "  \n",
        "# Release all space and windows once done\n",
        "cam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_s-bHefPc94",
        "outputId": "dd6d8721-5001-4377-cc91-763b4d3988d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame0.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame1.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame2.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame3.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame4.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame5.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame6.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame7.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame8.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame9.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame10.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame11.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame12.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame13.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame14.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame15.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame16.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame17.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame18.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame19.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame20.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame21.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame22.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame23.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame24.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame25.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame26.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame27.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame28.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame29.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame30.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame31.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame32.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame33.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame34.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame35.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame36.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame37.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame38.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame39.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame40.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame41.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame42.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame43.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame44.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame45.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame46.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame47.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame48.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame49.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame50.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame51.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame52.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame53.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame54.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame55.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame56.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame57.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame58.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame59.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame60.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame61.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame62.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame63.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame64.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame65.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame66.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame67.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame68.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame69.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame70.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame71.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame72.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame73.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame74.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame75.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame76.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame77.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame78.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame79.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame80.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame81.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame82.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame83.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame84.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame85.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame86.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame87.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame88.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame89.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame90.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame91.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame92.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame93.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame94.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame95.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame96.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame97.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame98.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame99.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame100.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame101.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame102.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame103.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame104.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame105.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame106.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame107.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame108.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame109.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame110.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame111.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame112.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame113.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame114.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame115.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame116.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame117.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame118.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame119.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame120.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame121.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame122.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame123.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame124.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame125.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame126.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame127.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame128.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame129.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame130.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame131.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame132.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame133.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame134.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame135.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame136.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame137.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame138.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame139.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame140.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame141.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame142.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame143.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame144.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame145.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame146.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame147.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame148.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame149.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame150.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame151.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame152.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame153.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame154.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame155.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame156.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame157.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame158.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame159.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame160.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame161.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame162.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame163.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame164.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame165.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame166.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame167.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame168.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame169.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame170.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame171.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame172.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame173.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame174.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame175.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame176.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame177.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame178.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame179.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame180.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame181.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame182.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame183.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame184.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame185.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame186.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame187.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame188.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame189.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame190.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame191.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame192.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame193.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame194.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame195.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame196.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame197.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame198.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame199.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame200.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame201.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame202.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame203.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame204.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame205.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame206.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame207.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame208.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame209.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame210.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame211.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame212.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame213.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame214.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame215.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame216.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame217.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame218.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame219.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame220.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame221.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame222.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame223.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame224.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame225.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame226.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame227.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame228.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame229.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame230.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame231.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame232.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame233.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame234.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame235.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame236.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame237.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame238.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame239.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame240.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame241.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame242.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame243.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame244.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame245.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame246.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame247.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame248.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame249.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame250.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame251.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame252.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame253.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame254.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame255.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame256.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame257.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame258.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame259.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame260.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame261.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame262.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame263.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame264.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame265.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame266.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame267.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame268.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame269.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame270.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame271.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame272.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame273.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame274.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame275.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame276.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame277.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame278.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame279.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame280.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame281.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame282.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame283.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame284.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame285.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame286.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame287.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame288.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame289.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame290.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame291.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame292.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame293.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame294.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame295.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame296.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame297.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame298.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame299.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame300.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame301.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame302.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame303.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame304.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame305.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame306.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame307.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame308.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame309.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame310.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame311.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame312.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame313.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame314.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame315.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame316.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame317.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame318.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame319.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame320.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame321.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame322.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame323.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame324.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame325.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame326.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame327.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame328.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame329.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame330.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame331.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame332.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame333.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame334.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame335.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame336.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame337.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame338.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame339.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame340.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame341.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame342.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame343.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame344.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame345.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame346.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame347.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame348.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame349.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame350.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame351.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame352.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame353.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame354.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame355.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame356.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame357.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame358.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame359.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame360.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame361.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame362.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame363.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame364.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame365.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame366.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame367.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame368.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame369.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame370.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame371.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame372.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame373.jpg\n",
            "Creating.../content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/frame374.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib as mpl\n",
        "\n",
        "mpl.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "IMAGE_DIR = '/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/'\n",
        "IMAGE_PATHS = glob.glob(os.path.join(IMAGE_DIR, '*.jp*g'))\n",
        "SAVE_DIR = '/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/'\n",
        "\n",
        "# Load model\n",
        "PATH_TO_SAVED_MODEL = '/content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/exported-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/saved_model'\n",
        "\n",
        "print('Loading model...', end='')\n",
        "start_time = time.time()\n",
        "\n",
        "# Load saved model and build the detection function\n",
        "detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print('Done! Took {} seconds'.format(elapsed_time))\n",
        "\n",
        "# Labels\n",
        "PATH_TO_LABELS = './annotations/label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(\n",
        "    PATH_TO_LABELS, use_display_name=True)\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "    \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "    Puts image into numpy array to feed into tensorflow graph.\n",
        "    Note that by convention we put it into a numpy array with shape\n",
        "    (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "    Args:\n",
        "      path: the file path to the image\n",
        "\n",
        "    Returns:\n",
        "      uint8 numpy array with shape (img_height, img_width, 3)\n",
        "    \"\"\"\n",
        "    return np.array(Image.open(path))\n",
        "\n",
        "\n",
        "for image_path in IMAGE_PATHS:\n",
        "    print('Running inference for {}... '.format(image_path), end='')\n",
        "\n",
        "    image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "    # Things to try:\n",
        "    # Flip horizontally\n",
        "    # image_np = np.fliplr(image_np).copy()\n",
        "\n",
        "    # Convert image to grayscale\n",
        "    # image_np = np.tile(\n",
        "    #     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
        "    input_tensor = tf.convert_to_tensor(image_np)\n",
        "    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
        "    input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "    # input_tensor = np.expand_dims(image_np, 0)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    # 以下参考 https://github.com/vijaydwivedi75/Custom-Mask-RCNN_TF/blob/master/mask_rcnn_eval.ipynb\n",
        "    # The following processing is only for single image\n",
        "    detection_boxes = tf.squeeze(detections['detection_boxes'], [0])\n",
        "    detection_masks = tf.squeeze(detections['detection_masks'], [0])\n",
        "    # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "    real_num_detection = tf.cast(detections['num_detections'][0], tf.int32)\n",
        "    detection_boxes = tf.slice(detection_boxes, [0, 0],\n",
        "                               [real_num_detection, -1])\n",
        "    detection_masks = tf.slice(detection_masks, [0, 0, 0],\n",
        "                               [real_num_detection, -1, -1])\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "        detection_masks, detection_boxes, image_np.shape[0], image_np.shape[1])\n",
        "    detection_masks_reframed = tf.cast(\n",
        "        tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "    # Follow the convention by adding back the batch dimension\n",
        "    detections['detection_masks'] = tf.expand_dims(detection_masks_reframed, 0)\n",
        "\n",
        "    detections['num_detections'] = int(detections['num_detections'][0])\n",
        "    detections['detection_classes'] = detections['detection_classes'][0].numpy(\n",
        "    ).astype(np.uint8)\n",
        "    detections['detection_boxes'] = detections['detection_boxes'][0].numpy()\n",
        "    detections['detection_scores'] = detections['detection_scores'][0].numpy()\n",
        "    detections['detection_masks'] = detections['detection_masks'][0].numpy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np_with_detections,\n",
        "        detections['detection_boxes'],\n",
        "        detections['detection_classes'],\n",
        "        detections['detection_scores'],\n",
        "        category_index,\n",
        "        instance_masks=detections.get('detection_masks'),\n",
        "        use_normalized_coordinates=True,\n",
        "        max_boxes_to_draw=200,\n",
        "        min_score_thresh=.30)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image_np_with_detections)\n",
        "\n",
        "    (filepath, filename) = os.path.split(image_path)\n",
        "    if not os.path.exists(SAVE_DIR):\n",
        "        os.makedirs(SAVE_DIR)\n",
        "    save_path = os.path.join(SAVE_DIR, filename)\n",
        "    plt.savefig(save_path)\n",
        "\n",
        "print('Done!')\n",
        "print(f'Annotated images is at {SAVE_DIR}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcir9u2uPdBd",
        "outputId": "6580ea5f-8767-4b26-a579-69b2b3ba1103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...Done! Took 42.47491788864136 seconds\n",
            "Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame0.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame1.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame2.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame3.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame4.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame5.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame6.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame7.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame8.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame9.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame10.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame11.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame12.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame13.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame14.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame15.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame16.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame17.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame18.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame19.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame20.jpg... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:112: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame21.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame22.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame23.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame24.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame25.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame26.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame27.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame28.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame29.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame30.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame31.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame32.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame33.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame34.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame35.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame36.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame37.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame38.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame39.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame40.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame41.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame42.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame43.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame44.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame45.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame46.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame47.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame48.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame49.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame50.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame51.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame52.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame53.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame54.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame55.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame56.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame57.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame58.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame59.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame60.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame61.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame62.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame63.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame64.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame65.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame66.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame67.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame68.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame69.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame70.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame71.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame72.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame73.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame74.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame75.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame76.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame77.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame78.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame79.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame80.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame81.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame82.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame83.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame84.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame85.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame86.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame87.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame88.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame89.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame90.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame91.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame92.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame93.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame94.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame95.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame96.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame97.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame98.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame99.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame100.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame101.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame102.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame103.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame104.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame105.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame106.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame107.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame108.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame109.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame110.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame111.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame112.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame113.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame114.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame115.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame116.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame117.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame118.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame119.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame120.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame121.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame122.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame123.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame124.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame125.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame126.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame127.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame128.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame129.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame130.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame131.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame132.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame133.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame134.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame135.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame136.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame137.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame138.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame139.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame140.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame141.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame142.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame143.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame144.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame145.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame146.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame147.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame148.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame149.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame150.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame151.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame152.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame153.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame154.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame155.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame156.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame157.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame158.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame159.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame160.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame161.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame162.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame163.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame164.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame165.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame166.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame167.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame168.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame169.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame170.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame171.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame172.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame173.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame174.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame175.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame176.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame177.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame178.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame179.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame180.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame181.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame182.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame183.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame184.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame185.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame186.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame187.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame188.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame189.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame190.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame191.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame192.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame193.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame194.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame195.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame196.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame197.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame198.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame199.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame200.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame201.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame202.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame203.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame204.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame205.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame206.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame207.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame208.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame209.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame210.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame211.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame212.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame213.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame214.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame215.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame216.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame217.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame218.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame219.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame220.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame221.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame222.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame223.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame224.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame225.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame226.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame227.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame228.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame229.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame230.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame231.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame232.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame233.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame234.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame235.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame236.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame237.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame238.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame239.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame240.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame241.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame242.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame243.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame244.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame245.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame246.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame247.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame248.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame249.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame250.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame251.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame252.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame253.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame254.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame255.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame256.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame257.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame258.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame259.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame260.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame261.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame262.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame263.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame264.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame265.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame266.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame267.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame268.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame269.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame270.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame271.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame272.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame273.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame274.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame275.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame276.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame277.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame278.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame279.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame280.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame281.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame282.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame283.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame284.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame285.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame286.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame287.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame288.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame289.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame290.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame291.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame292.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame293.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame294.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame295.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame296.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame297.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame298.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame299.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame300.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame301.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame302.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame303.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame304.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame305.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame306.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame307.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame308.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame309.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame310.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame311.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame312.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame313.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame314.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame315.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame316.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame317.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame318.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame319.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame320.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame321.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame322.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame323.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame324.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame325.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame326.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame327.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame328.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame329.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame330.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame331.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame332.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame333.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame334.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame335.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame336.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame337.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame338.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame339.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame340.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame341.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame342.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame343.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame344.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame345.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame346.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame347.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame348.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame349.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame350.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame351.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame352.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame353.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame354.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame355.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame356.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame357.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame358.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame359.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame360.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame361.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame362.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame363.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame364.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame365.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame366.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame367.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame368.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame369.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame370.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame371.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame372.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame373.jpg... Running inference for /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Input/frames/frame374.jpg... Done!\n",
            "Annotated images is at /content/drive/MyDrive/Dress_Code_Tf_Mask_RCNN/object-detection-api/workspace/Dress-Code/Output/frames/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ky5H4aMSPdFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Cd2hZBqoPdHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gDp5h0J7OOPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_fps(video):\n",
        "  # Find OpenCV version\n",
        "  (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
        "\n",
        "  if int(major_ver)  < 3 :\n",
        "      fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
        "      print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
        "  else :\n",
        "      fps = video.get(cv2.CAP_PROP_FPS)\n",
        "      print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
        "\n",
        "\n",
        "def make_video(outvid, images=None, fps=30, size=None,\n",
        "               is_color=True, format=\"FMP4\"):\n",
        "    \"\"\"\n",
        "    Create a video from a list of images.\n",
        " \n",
        "    @param      outvid      output video\n",
        "    @param      images      list of images to use in the video\n",
        "    @param      fps         frame per second\n",
        "    @param      size        size of each frame\n",
        "    @param      is_color    color\n",
        "    @param      format      see http://www.fourcc.org/codecs.php\n",
        "    @return                 see http://opencv-python-tutroals.readthedocs.org/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html\n",
        " \n",
        "    The function relies on http://opencv-python-tutroals.readthedocs.org/en/latest/.\n",
        "    By default, the video will have the size of the first image.\n",
        "    It will resize every image to this size before adding them to the video.\n",
        "    \"\"\"\n",
        "    from cv2 import VideoWriter, VideoWriter_fourcc, imread, resize\n",
        "    fourcc = VideoWriter_fourcc(*format)\n",
        "    vid = None\n",
        "    for image in images:\n",
        "        img = imread(image)\n",
        "        if vid is None:\n",
        "            if size is None:\n",
        "                size = img.shape[1], img.shape[0]\n",
        "            vid = VideoWriter(outvid, fourcc, float(fps), size, is_color)\n",
        "        if size[0] != img.shape[1] and size[1] != img.shape[0]:\n",
        "            img = resize(img, size)\n",
        "        vid.write(img)\n",
        "    vid.release()\n",
        "    return vid"
      ],
      "metadata": {
        "id": "YA1Yn4HbB-gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# number of images to be processed at once\n",
        "batch_size = 3\n",
        "\n",
        "class InferenceConfig(coco.CocoConfig):\n",
        "    GPU_COUNT = 1\n",
        "    IMAGES_PER_GPU = batch_size\n",
        "\n",
        "config = InferenceConfig()\n",
        "config.display()\n",
        "\n",
        "model = modellib.MaskRCNN(\n",
        "    mode=\"inference\", model_dir=MODEL_DIR, config=config\n",
        ")\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "CLASS_NAMES_MASKRCNN = "
      ],
      "metadata": {
        "id": "3drQP5Lnyi7l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}